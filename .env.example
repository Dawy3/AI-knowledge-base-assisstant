# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# Provider: openrouter, openai, or local
LLM_PROVIDER=openrouter
LLM_MODEL=openai/gpt-4o-mini

# API Keys (set the one for your provider)
OPENAI_API_KEY=sk-your-openai-api-key
OPENROUTER_API_KEY=sk-or-your-openrouter-key

# Base URLs (optional)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENAI_BASE_URL=https://api.openai.com/v1
LOCAL_LLM_URL=http://localhost:8080/v1

# Tier Models (OpenAI only - for cost optimization)
# LLM_TIER1_MODEL=gpt-3.5-turbo
# LLM_TIER2_MODEL=gpt-4o-mini
# LLM_TIER3_MODEL=gpt-4

# Generation Parameters
# LLM_MAX_TOKENS=1024
# LLM_TEMPERATURE=0.7
# LLM_TIMEOUT=30.0

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# Provider: openai, huggingface, cohere
EMBEDDING_MODEL_PROVIDER=huggingface
EMBEDDING_MODEL_NAME=e5-large-v2
EMBEDDING_DIMENSIONS=1024
# EMBEDDING_BATCH_SIZE=100
# EMBEDDING_TIMEOUT=30.0

# HuggingFace Token (for huggingface provider)
HF_TOKEN=hf_your-huggingface-token

# =============================================================================
# VECTOR STORE
# =============================================================================
# Options: qdrant, pinecone, pgvector
VECTOR_STORE=qdrant

# Qdrant (local or cloud)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your-qdrant-api-key
QDRANT_COLLECTION=documents

# Pinecone (alternative)
# PINECONE_API_KEY=your-pinecone-api-key
# PINECONE_INDEX_NAME=my-app-index
# PINECONE_ENVIRONMENT=us-east-1

# =============================================================================
# POSTGRESQL
# =============================================================================
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag_db
# POSTGRES_POOL_SIZE=10

# =============================================================================
# REDIS CACHE
# =============================================================================
REDIS_URL=redis://localhost:6379/0
# REDIS_MAX_CONNECTIONS=10

# =============================================================================
# RETRIEVAL PIPELINE
# =============================================================================
CHUNK_SIZE=512
CHUNK_OVERLAP=50
VECTOR_TOP_K=100
RERANK_TOP_K=10
VECTOR_WEIGHT=5.0
BM25_WEIGHT=3.0
RECENCY_WEIGHT=0.2
RELEVANCE_THRESHOLD=0.6

# =============================================================================
# APPLICATION
# =============================================================================
APP_ENV=development
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# =============================================================================
# OBSERVABILITY (Optional)
# =============================================================================
# LANGSMITH_API_KEY=lsv2_pt_xxx
# LANGSMITH_PROJECT=my-rag-project
# METRICS_ENABLED=true
# METRICS_PORT=9090
# TRACING_ENABLED=true
# TRACING_ENDPOINT=http://localhost:4317
